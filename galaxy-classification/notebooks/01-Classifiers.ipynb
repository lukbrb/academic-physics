{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aef93a7-c543-4ebb-8c88-08630e53b320",
   "metadata": {},
   "source": [
    "# 1. Classification\n",
    "\n",
    "Presentation of some algorithms. We will here use some classifiers commonly used. The classifiers we compare here are the following :\n",
    "- [The K-Nearest Neighbors (KNN) Classifier](#1.1-K-Nearest-Neighbors)\n",
    "- [Support Vector Machine (SVM)](#1.2-Support-Vector-Machine)\n",
    "- [Gaussian Process Classifier](#1.3-Gaussian-Process-Classifier)\n",
    "- [Decision Tree Classifier](#1.4-Decision-Tree-Classifier)\n",
    "- [Random Forest Classifier](#1.5-Random-Forest-Classifier)\n",
    "- [The Ada Boost Classifier](#1.6-Ada-Boost-Classifier)\n",
    "- [Naive Bayes Classifier](#1.7-Naive-Bayes-Classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636205cc-0a11-452c-88cb-46ea74bdd077",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 K-Nearest Neighbors\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4842e-67c4-41c8-ba9f-2e9217ca4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lblearn.datasets import load_galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dbc0a8-ede6-4926-a9b5-d3bb53fd3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=150)  # 150 of each species\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "model = KNeighborsClassifier(3)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(accuracy_score(y_pred=predictions, y_true=y_test))\n",
    "print(np.sum(predictions == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eea61a-273f-473b-bdd1-90073cf5f8d8",
   "metadata": {},
   "source": [
    "The accuracy is better than random, but is still poor. To improve it, we can try to change some hyperparameters, such as the number of neighbor. Before doing so, we first try to scale the data. Indeed, the column `NVOTE`has large values whereas all the others are probabilities ranging from 0 to 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21957feb-5013-426e-b36e-610c7d767130",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=150)  # 150 of each species\n",
    "X, y = galaxies.data, galaxies.target\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "scaler.fit(X_train[:, 0].reshape(-1, 1))  \n",
    "X_train[:, 0] = scaler.transform(X_train[:, 0].reshape(-1, 1)).flatten()  # All data is between 0 and 1 but NVOTE\n",
    "scaler_test.fit(X_test[:, 0].reshape(-1, 1))  \n",
    "X_test[:, 0] = scaler_test.transform(X_test[:, 0].reshape(-1, 1)).flatten()\n",
    "\n",
    "model = KNeighborsClassifier(7)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_pred=predictions, y_true=y_test)\n",
    "print(score)\n",
    "print(np.sum(predictions == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d593008c-ac25-46a5-a2ae-d20bf4199d07",
   "metadata": {},
   "source": [
    "The accuracy score is a precious indicator on the performance of our model. However it does not indicate where the model has gone wrong. A good alternative to it is the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdc91c-b217-4f4d-bc39-c15389f95f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"KNN, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86da2d-f28c-4840-9451-f3cd632e58f6",
   "metadata": {},
   "source": [
    "Sklearn also implements grid search methods to find the best set of parameters for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c022d6-1565-4b15-93f4-c850f4be2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb55df3-451b-4c0e-8860-c715bb6904e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "scaler.fit(X_train[:, 0].reshape(-1, 1))  \n",
    "X_train[:, 0] = scaler.transform(X_train[:, 0].reshape(-1, 1)).flatten()  # All data is between 0 and 1 but NVOTE\n",
    "scaler_test.fit(X_test[:, 0].reshape(-1, 1))  \n",
    "X_test[:, 0] = scaler_test.transform(X_test[:, 0].reshape(-1, 1)).flatten()\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "k_range = list(range(1, 15))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', return_train_score=True, verbose=3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6cf47-8845-4b8b-9095-573daa26d834",
   "metadata": {},
   "source": [
    "Altough the sklearn API is nicely designed and quite intuitive, adding all these steps can become quite tedious. This is particularly true when changing the type of classifier, all the lines have to be rewritten. Luckily enough, sklearn provide a nice way to overcome this difficulty: the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff9b76-5236-4773-8458-117a265951bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb0d2e-8f87-423f-b9f4-a620f2b63676",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifier = KNeighborsClassifier(7)\n",
    "clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"KNN, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9dd75-b73c-47c2-85d8-28cffa35d7d3",
   "metadata": {},
   "source": [
    "## 1.2 Support Vector Machine\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534bd48-5811-4010-9610-fb942ce9fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ba256-60fd-4b21-b24d-080999e194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train[:, 0].reshape(-1, 1))  \n",
    "X_train[:, 0] = scaler.transform(X_train[:, 0].reshape(-1, 1)).flatten()  # All data is between 0 and 1 but NVOTE\n",
    "scaler_test.fit(X_test[:, 0].reshape(-1, 1))  \n",
    "X_test[:, 0] = scaler_test.transform(X_test[:, 0].reshape(-1, 1)).flatten()\n",
    "\n",
    "classifier = SVC()\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000, 1500, 10_000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000, 1500, 10_000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ] \n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', return_train_score=True, verbose=1)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4579437b-0534-4235-adbc-553f7a56176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifier = SVC(kernel='linear', C=1000)\n",
    "clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"SVC, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f40bca-cab8-4ad9-9828-451c6c2c1aa8",
   "metadata": {},
   "source": [
    "## 1.3 Gaussian Process Classifier\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77baece9-ecbf-42f1-a942-46052a4f57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, DotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfec5bb-6aef-483f-910d-f09f269cf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train[:, 0].reshape(-1, 1))  \n",
    "X_train[:, 0] = scaler.transform(X_train[:, 0].reshape(-1, 1)).flatten()  # All data is between 0 and 1 but NVOTE\n",
    "scaler_test.fit(X_test[:, 0].reshape(-1, 1))  \n",
    "X_test[:, 0] = scaler_test.transform(X_test[:, 0].reshape(-1, 1)).flatten()\n",
    "\n",
    "classifier = GaussianProcessClassifier()\n",
    "\n",
    "param_grid = [{\n",
    "    \"kernel\": [RBF(l) for l in np.logspace(-1, 1, 10)]\n",
    "}, {\n",
    "    \"kernel\": [DotProduct(sigma_0) for sigma_0 in np.logspace(-1, 1, 10)]\n",
    "}]\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e2039-d9ad-4ad2-b63e-1f4a26bfbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifier = GaussianProcessClassifier(DotProduct(0.1))\n",
    "clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"Gaussian process, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d89638a-0243-40fb-be28-3d606dab28c0",
   "metadata": {},
   "source": [
    "## 1.4 Decision Tree Classifier\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53186096-e203-45bb-bd9f-b314dd42d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c22bcc4-a9c8-4941-af3b-fe572cbc5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train[:, 0].reshape(-1, 1))  \n",
    "X_train[:, 0] = scaler.transform(X_train[:, 0].reshape(-1, 1)).flatten()  # All data is between 0 and 1 but NVOTE\n",
    "scaler_test.fit(X_test[:, 0].reshape(-1, 1))  \n",
    "X_test[:, 0] = scaler_test.transform(X_test[:, 0].reshape(-1, 1)).flatten()\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = [\n",
    "    {'criterion': ['entropy', 'gini', 'log_loss'], 'max_depth': list(range(5, 30))}\n",
    "             ]\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227aacd1-8259-42cf-8f9c-9d96fa21b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', max_depth=28)\n",
    "clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"Decision Tree, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc385c-0587-4ad1-bf55-136630a4a8e6",
   "metadata": {},
   "source": [
    "## 1.5 Random Forest Classifier\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f78b1d-6aa7-4137-aa42-3b2b87bd0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc7507-5d77-46d2-9ae5-7b4e47434212",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_test = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train[:, 0].reshape(-1, 1))  \n",
    "X_train[:, 0] = scaler.transform(X_train[:, 0].reshape(-1, 1)).flatten()  # All data is between 0 and 1 but NVOTE\n",
    "scaler_test.fit(X_test[:, 0].reshape(-1, 1))  \n",
    "X_test[:, 0] = scaler_test.transform(X_test[:, 0].reshape(-1, 1)).flatten()\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "param_grid = [\n",
    "    {'criterion': ['entropy', 'gini', 'log_loss'], 'max_depth': list(range(20, 40)),\n",
    "     'n_estimators' : [20, 30]\n",
    "    }\n",
    "             ]\n",
    "\n",
    "grid = GridSearchCV(classifier, param_grid, cv=10, scoring='accuracy', return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84b039-a31a-46d4-bb38-c43298314bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=30, criterion='entropy', max_depth=35)\n",
    "clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"Random Forest, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796d2d6-bc0f-49e6-a6bb-8b7aa3a4b174",
   "metadata": {},
   "source": [
    "## 1.6 Perceptron\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589a6e3-e88a-43eb-815e-eb07e4e701ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b584c-14d4-451c-9498-0ac171886bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "param_grid = [{\n",
    "    'clf__tol': [1e-1, 1e-3, 1e-5],\n",
    "    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'clf__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "    'clf__eta0': [1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "}]\n",
    "\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()), ('clf', Perceptron())])\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid,scoring='accuracy', cv=5, return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6f78e-48c6-4d16-9555-f42e749f0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifier = Perceptron(alpha=0.001, eta0=0.0001, penalty='l1', tol=0.1)\n",
    "clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"Perceptron, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed99c36-da92-4fa8-a323-f60fa50ba371",
   "metadata": {},
   "source": [
    "## 1.8 Ada Boost Classifier\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ef41e2-f6c3-45b0-8d12-003065dfd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89faace5-63a3-4362-91cf-63c038c35f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "\n",
    "parameters = {'base_estimator__max_depth':[i for i in range(2,11,2)],\n",
    "              'base_estimator__min_samples_leaf':[5,10],\n",
    "              'n_estimators':[10,50,250,1000],\n",
    "              'learning_rate':[0.01,0.1]}\n",
    "\n",
    "clf = GridSearchCV(abc, parameters,verbose=3,scoring='f1',n_jobs=-1)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2018165-de24-4ecd-82f7-0314d617ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "pipe = Pipeline([('scale', StandardScaler()), ('clf', AdaBoostClassifier(estimator=DecisionTreeClassifier()))])\n",
    "\n",
    "param_grid = {'clf__estimator__max_depth':list(range(1, 30)),\n",
    "              'clf__estimator__criterion':['entropy', 'gini', 'log_loss'],\n",
    "              'clf__n_estimators':[10, 50, 250, 1000],\n",
    "              'clf__learning_rate':[0.01, 0.1]} \n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='accuracy', cv=5, return_train_score=True, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bf24a-d5dc-4977-8bd1-df7aa4f5a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(criterion='entropy', max_depth=3), learning_rate=0.1, n_estimators=250)\n",
    "clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "score = accuracy_score(y_test, predictions)\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "disp.figure_.suptitle(f\"Perceptron, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995145c-c74e-4ac8-9fe8-c398fc144721",
   "metadata": {},
   "source": [
    "## 1.9 Naive Bayes Classifier\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc673ec-0cf1-4e70-b001-c3218d063365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB, CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac1a582-7095-47bf-8900-96d034b81374",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies = load_galaxies(n_samples=100)\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "classifiers = [GaussianNB(), MultinomialNB(), BernoulliNB(), ComplementNB()] #, CategoricalNB()]\n",
    "\n",
    "\n",
    "for classifier in classifiers:\n",
    "    # pipeline = Pipeline([('scale', MinMaxScaler()), ('clf', classifier)])\n",
    "    clf = make_pipeline(MinMaxScaler(), classifier)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, predictions)\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_test, predictions)\n",
    "    disp.figure_.suptitle(f\"{classifier.__class__.__name__}, accuracy ={score: .2f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7285c1c-8c8f-45ec-93ca-9700db32e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "# https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d562c69-a5ec-43d1-95b3-b6db71891e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "dataset = {}\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf = make_pipeline(StandardScaler(), clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    # disp = ConfusionMatrixDisplay.from_predictions\n",
    "    cm = confusion_matrix(y_test, predicted)\n",
    "\n",
    "# For each cell in the confusion matrix, add the corresponding ground truths\n",
    "# and predictions to the lists\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for gt in range(len(cm)):\n",
    "        for pred in range(len(cm)):\n",
    "            y_true += [gt] * cm[gt][pred]\n",
    "            y_pred += [pred] * cm[gt][pred]\n",
    "\n",
    "    print(\n",
    "        f\"Classification report rebuilt from confusion matrix for {name}:\\n\"\n",
    "        f\"{classification_report(y_true, y_pred)}\\n\"\n",
    "    )\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    dataset[name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91968e0c-a100-458d-90ad-e4baf804f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = classification_report(y_true, y_pred)\n",
    "# Supprimez les retours à la ligne et les espaces en début et en fin de chaîne\n",
    "output = output.strip()\n",
    "\n",
    "# Divisez la chaîne de caractères en lignes\n",
    "lines = output.split('\\n')\n",
    "\n",
    "# Divisez chaque ligne en colonnes\n",
    "data = [line.split() for line in lines]\n",
    "data[1:-1]\n",
    "# Créez une liste de listes qui représente les données de la table\n",
    "#table_data = [data[0]] + [[float(x) if '.' in x else int(x) for x in row] for row in data[1:-1]] + [data[-1]]\n",
    "\n",
    "# Créez une DataFrame pandas à partir de cette liste de listes\n",
    "#df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "\n",
    "# Affichez la DataFrame pandas à l'aide de la méthode display()\n",
    "#display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61395a8-fec2-4f72-bcda-1fecdd93cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dict(reversed(sorted(dataset.items(), key=lambda item: item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f36f3-ad91-41a2-8846-78e1bf50cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "# Créer un dataframe de test\n",
    "#df = pd.DataFrame({'Nom': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]})\n",
    "df_scores = pd.DataFrame(dataset.items(), columns=['Algorithm', 'Score'])\n",
    "# Afficher le dataframe en Markdown\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1001f8-86b3-499e-a5bb-c213068751c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess dataset, split into training and test part\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf = make_pipeline(StandardScaler(), clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "    #print(f\"Confusion matrix:\\n{disp.confusion_matrix}\")\n",
    "    disp.figure_.suptitle(f\"{name}, accuracy={score: .2f}\");\n",
    "    #plt.imshow(confusion_matrix(y_test, y_pred),cmap='Blues', interpolation='nearest')\n",
    "    #plt.grid(False)\n",
    "    #plt.ylabel('True')\n",
    "    #plt.xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c9bff-1577-47bb-a2fa-b65aae298b13",
   "metadata": {},
   "source": [
    "In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix,[11] is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix). Each row of the matrix represents the instances in an actual class while each column represents the instances in a predicted class, or vice versa – both variants are found in the literature.[12] The name stems from the fact that it makes it easy to see whether the system is confusing two classes (i.e. commonly mislabeling one as another).\n",
    "\n",
    "It is a special kind of contingency table, with two dimensions (\"actual\" and \"predicted\"), and identical sets of \"classes\" in both dimensions (each combination of dimension and class is a variable in the contingency table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba8c36-abf7-485f-9052-b01cefa1b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "x_index = 5\n",
    "y_index = 7\n",
    "# preprocess dataset, split into training and test part\n",
    "X, y = galaxies.data, galaxies.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "# just plot the dataset first\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "if ds_cnt == 0:\n",
    "    ax.set_title(\"Input data\")\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, x_index], X_train[:, y_index], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "# Plot the testing points\n",
    "ax.scatter(\n",
    "    X_test[:, x_index], X_test[:, y_index], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors=\"k\"\n",
    ")\n",
    "#ax.set_xlim(x_min, x_max)\n",
    "#ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(), clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    #DecisionBoundaryDisplay.from_estimator(\n",
    "        #clf, X[:, 2:4], cmap=cm, alpha=0.8, ax=ax, eps=0.5\n",
    "    #)\n",
    "\n",
    "    # Plot the training points\n",
    "    ax.scatter(\n",
    "        X_train[:, x_index], X_train[:, y_index], c=y_train, cmap=cm_bright, edgecolors=\"k\"\n",
    "    )\n",
    "    # Plot the testing points\n",
    "    ax.scatter(\n",
    "        X_test[:, x_index],\n",
    "        X_test[:, y_index],\n",
    "        c=y_test,\n",
    "        cmap=cm_bright,\n",
    "        edgecolors=\"k\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "\n",
    "    #ax.set_xlim(x_min, x_max)\n",
    "    #ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(name)\n",
    "    ax.text(\n",
    "        x_max - 0.3,\n",
    "        y_min + 0.3,\n",
    "        (\"%.2f\" % score).lstrip(\"0\"),\n",
    "        size=15,\n",
    "        horizontalalignment=\"right\",\n",
    "    )\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1dc64-6537-4784-b62c-30cd0d88480f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
